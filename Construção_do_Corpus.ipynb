{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRnizDR2KKh3W8yHWdHZ70",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Purkott/Construcao-de-corpus/blob/main/Constru%C3%A7%C3%A3o_do_Corpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sua  tarefa  será  transformar  um  conjunto  de  5  sites,  sobre  o  tema  de  processamento  de \n",
        "linguagem natural em um conjunto de cinco listas distintas de sentenças. Ou seja, você fará uma função \n",
        "que, usando a biblioteca Beautifull Soap, faça a requisição de uma url, e extrai todas as sentenças desta \n",
        "url. Duas condições são importantes:  \n",
        "a) A página web (url) deve apontar para uma página web em inglês contendo, não menos que \n",
        "1000 palavras.  \n",
        "b) O texto desta página deverá ser transformado em um array de senteças.  \n",
        " \n",
        "Para separar as sentenças você pode usar os sinais de pontuação ou as funções da biblibioteca \n",
        "Spacy. "
      ],
      "metadata": {
        "id": "OdZN3Pk4wXhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Aluno: Fernando Purkott\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import spacy\n",
        "from spacy.language import Language\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "@Language.component(\"Space\")\n",
        "def set_custom_boundaries(doc):\n",
        "     for token in doc[:-1]:\n",
        "         if token.text.__contains__('  '):\n",
        "             doc[token.i+1].is_sent_start = True\n",
        "     return doc\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.add_pipe('Space', before=\"parser\")\n",
        "\n",
        "def excluiNovaLinha(value):\n",
        "    return ''.join(value.splitlines())\n",
        "\n",
        "\n",
        "\n",
        "blacklist = [\n",
        "    '[document]',\n",
        "    'noscript',\n",
        "    'header',\n",
        "    'html',\n",
        "    'meta',\n",
        "    'head', \n",
        "    'input',\n",
        "    'script',\n",
        "    'style'\n",
        "]\n",
        "\n",
        "def scrape(URL):\n",
        "  blacklist = [\n",
        "    '[document]',\n",
        "    'noscript',\n",
        "    'header',\n",
        "    'html',\n",
        "    'meta',\n",
        "    'head', \n",
        "    'input',\n",
        "    'script',\n",
        "    'style'\n",
        "  ]\n",
        "\n",
        "  req = requests.get(URL)\n",
        "  soup = BeautifulSoup(req.content)\n",
        "\n",
        "\n",
        "  txt = soup.find_all(text=True)\n",
        "  clean_txt = \"\"\n",
        "\n",
        "  for t in txt:\n",
        "    if t.parent.name not in blacklist:\n",
        "        clean_txt += '{} '.format(t)\n",
        "\n",
        "  txt_doc = nlp(excluiNovaLinha(clean_txt))\n",
        "\n",
        "\n",
        "  sentences = list(txt_doc.sents)\n",
        "  return sentences\n",
        "\n",
        "# \"https://www.ibm.com/cloud/learn/natural-language-processing\"\n",
        "\n",
        "sentences1 = scrape(\"https://www.ibm.com/cloud/learn/natural-language-processing\")\n",
        "sentences2 = scrape(\"https://hbr.org/2022/04/the-power-of-natural-language-processing\")\n",
        "sentences3 = scrape(\"https://link.springer.com/article/10.1007/s11042-022-13428-4\")\n",
        "sentences4 = scrape(\"https://www.techtarget.com/searchenterpriseai/definition/natural-language-processing-NLP\")\n",
        "sentences5 = scrape(\"https://monkeylearn.com/natural-language-processing/\")\n",
        "\n",
        "for sentence in sentences1:\n",
        "  print (sentence)\n",
        "\n",
        "for sentence in sentences2:\n",
        "  print (sentence)\n",
        "\n",
        "for sentence in sentences3:\n",
        "  print (sentence)\n",
        "\n",
        "for sentence in sentences4:\n",
        "  print (sentence)\n",
        "\n",
        "for sentence in sentences5:\n",
        "  print (sentence)\n",
        "\n"
      ],
      "metadata": {
        "id": "nIbYFUhUMiG8"
      },
      "execution_count": 56,
      "outputs": []
    }
  ]
}